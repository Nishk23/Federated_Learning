{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-17T08:40:41.011042Z",
     "start_time": "2024-06-17T08:40:27.751241Z"
    }
   },
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import evaluate\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from transformers import AutoImageProcessor, ResNetForImageClassification\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, Label, Button\n",
    "\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T08:40:43.685856Z",
     "start_time": "2024-06-17T08:40:43.673361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a custom dataset\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, label, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.label"
   ],
   "id": "fadf20bf56c05d2c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T08:40:45.612098Z",
     "start_time": "2024-06-17T08:40:45.596931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define transformation with data augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ],
   "id": "176bc2b45b0d9520",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T08:40:48.090765Z",
     "start_time": "2024-06-17T08:40:48.046772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "root = 'C:/Users/nithi/Desktop/FAU/Semester-4/Master_Thesis_Federated_Learning/Dataset/sample/images'\n",
    "\n",
    "# Create datasets\n",
    "train_atelectasis = CustomImageDataset(root + '/Atelectasis/train', 0, train_transform)\n",
    "train_cardiomegaly = CustomImageDataset(root + '/Cardiomegaly/train', 1, train_transform)\n",
    "val_atelectasis = CustomImageDataset(root + '/Atelectasis/val', 0, val_test_transform)\n",
    "val_cardiomegaly = CustomImageDataset(root + '/Cardiomegaly/val', 1, val_test_transform)\n",
    "test_atelectasis = CustomImageDataset(root + '/Atelectasis/test', 0, val_test_transform)\n",
    "test_cardiomegaly = CustomImageDataset(root + '/Cardiomegaly/test', 1, val_test_transform)"
   ],
   "id": "b346e63bc2a3c7f3",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T08:41:07.408777Z",
     "start_time": "2024-06-17T08:40:50.842863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Combine train datasets and calculate class weights\n",
    "train_dataset = train_atelectasis + train_cardiomegaly\n",
    "class_counts = Counter([label for _, label in train_dataset])\n",
    "class_weights = {0: 1.0 / class_counts[0], 1: 1.0 / class_counts[1]}\n",
    "sample_weights = [class_weights[label] for _, label in train_dataset]\n",
    "sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
    "\n",
    "val_dataset = val_atelectasis + val_cardiomegaly\n",
    "test_dataset = test_atelectasis + test_cardiomegaly\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, sampler=sampler)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ],
   "id": "701e3ab3085f9f7c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T08:41:13.416675Z",
     "start_time": "2024-06-17T08:41:12.125186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load pre-trained model and processor\n",
    "processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\", num_labels=2, ignore_mismatched_sizes=True)\n",
    "model.config.id2label = {0: 'Atelectasis', 1: 'Cardiomegaly'}\n",
    "model.config.label2id = {'Atelectasis': 0, 'Cardiomegaly': 1}\n",
    "\n",
    "# Add dropout for regularization\n",
    "model.classifier.dropout = torch.nn.Dropout(p=0.5)\n",
    "\n",
    "# Define training parameters\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor([class_weights[0], class_weights[1]]).to(device))"
   ],
   "id": "cfbfd326b78befde",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-50 and are newly initialized because the shapes did not match:\n",
      "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.1.weight: found shape torch.Size([1000, 2048]) in the checkpoint and torch.Size([2, 2048]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T08:41:15.589548Z",
     "start_time": "2024-06-17T08:41:15.557758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training loop with early stopping\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10, patience=3):\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(pixel_values=images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(pixel_values=images).logits\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping\")\n",
    "                break"
   ],
   "id": "dc283ecec3aaa58c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T08:55:24.609998Z",
     "start_time": "2024-06-17T08:41:20.731907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10)"
   ],
   "id": "c3b1404bf5d23e8f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.6199410023360417, Val Loss: 0.9108462631702423\n",
      "Epoch 2/10, Train Loss: 0.5802430644117552, Val Loss: 1.0615930344377245\n",
      "Epoch 3/10, Train Loss: 0.5157384379156704, Val Loss: 1.2677611815077918\n",
      "Epoch 4/10, Train Loss: 0.4812785782690706, Val Loss: 0.6747127260480609\n",
      "Epoch 5/10, Train Loss: 0.4943594254296401, Val Loss: 1.1991265820605415\n",
      "Epoch 6/10, Train Loss: 0.4770188023304117, Val Loss: 0.8957285971513816\n",
      "Epoch 7/10, Train Loss: 0.4847736492239196, Val Loss: 0.7801030831677573\n",
      "Early stopping\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T08:56:15.149873Z",
     "start_time": "2024-06-17T08:56:14.956099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_model.pt'))"
   ],
   "id": "830f87bb47b06ce9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T08:56:28.303190Z",
     "start_time": "2024-06-17T08:56:19.224090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate the model\n",
    "metric = evaluate.load(\"accuracy\", trust_remote_code=True)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(pixel_values=images).logits\n",
    "        predictions = torch.argmax(outputs, dim=-1)\n",
    "        metric.add_batch(predictions=predictions, references=labels)\n",
    "\n",
    "accuracy = metric.compute()['accuracy']\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ],
   "id": "8bb922d1e0168f8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5858585858585859\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T08:56:40.993831Z",
     "start_time": "2024-06-17T08:56:40.980786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Predict using the trained model\n",
    "def predict_image(image_path, model, processor):\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image path {image_path} does not exist.\")\n",
    "        return None\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    predicted_label = logits.argmax(-1).item()\n",
    "    return model.config.id2label[predicted_label]\n"
   ],
   "id": "b21fa158d226b186",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T08:58:29.836300Z",
     "start_time": "2024-06-17T08:58:02.080262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# GUI to select an image and predict\n",
    "def open_file():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        label.config(text=f\"Selected image: {file_path}\")\n",
    "        predicted_label = predict_image(file_path, model, processor)\n",
    "        result_label.config(text=f\"Predicted label: {predicted_label}\")\n",
    "        \n",
    "# Create the GUI application\n",
    "root = tk.Tk()\n",
    "root.title(\"Image Classification\")\n",
    "\n",
    "label = Label(root, text=\"Select an image to classify\")\n",
    "label.pack(pady=10)\n",
    "\n",
    "button = Button(root, text=\"Select Image\", command=open_file)\n",
    "button.pack(pady=10)\n",
    "\n",
    "result_label = Label(root, text=\"\")\n",
    "result_label.pack(pady=10)\n",
    "\n",
    "root.mainloop()"
   ],
   "id": "5e4894cf00e9a4f5",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cd8b9a41e76cbdcd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
